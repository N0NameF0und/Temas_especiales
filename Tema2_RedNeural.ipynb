{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos todas las librerias nescesarias \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "SAMPLES = 1000\n",
    "\n",
    "#Usamos un seed para resultados reproducibles\n",
    "SEED = 570\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "#Generamos la muestras\n",
    "x_values = np.random.uniform(low=0, high=2*math.pi, size=SAMPLES)\n",
    "np.random.shuffle(x_values)\n",
    "y_values = np.sin(x_values)\n",
    "\n",
    "#Creamos la primer grafica\n",
    "plt.plot(x_values, y_values, 'b.')\n",
    "plt.show()\n",
    "\n",
    "#Añadimos ruido a los valores en y\n",
    "y_values += 0.1 * np.random.randn(*y_values.shape)\n",
    "\n",
    "#Dividimos el dataset para los modelos validacion, testeo y entrenamiento,\n",
    "#creamos indices y dividimos los valores\n",
    "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
    "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
    "x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "#verificacion\n",
    "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
    "\n",
    "#Mostramos los datos que vamos a usar \n",
    "plt.plot(x_train, y_train, 'b.', label=\"Entrenar \")\n",
    "plt.plot(x_validate, y_validate, 'y.', label=\"Validar\")\n",
    "plt.plot(x_test, y_test, 'r.', label=\"testear\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#Creamos los modelos y capa de entrada\n",
    "model_1 = tf.keras.Sequential()\n",
    "model_1.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
    "\n",
    "#Añadimos las capas con las neuronas y usamos optimos loss y regresion function\n",
    "model_1.add(layers.Dense(1))\n",
    "model_1.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "#1er capa 16 neuronas 2 capa 1 neurona 16 conexioenes =32 , 17 neuronas 17 bias\n",
    "#49 parametros\n",
    "model_1.summary()\n",
    "\n",
    "#Comienzo de entrenamiento\n",
    "history_1 = model_1.fit(x_train, y_train, epochs=1000, batch_size=16,\n",
    "                     validation_data=(x_validate, y_validate))\n",
    "\n",
    "#Graficamos la perdida , epoch \n",
    "loss = history_1.history['loss']\n",
    "val_loss = history_1.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Perdida en entrenamiento y validacion')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Perdida')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HACEMOS UN GRAFICO SIN LOS PRIMEROS 100 REGISTROS \n",
    "#usando los valores de loss normal y mae\n",
    "SKIP = 100\n",
    "\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Perdida en entrenamiento y validacion')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "mae = history_1.history['mae']\n",
    "val_mae = history_1.history['val_mae']\n",
    "\n",
    "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Error Absoluto entrenamiento y validacion')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos el modelo creado para hacer predicciones\n",
    "predictions = model_1.predict(x_train)\n",
    "plt.clf()\n",
    "plt.title('Datos predecidos vs datos reales ')\n",
    "plt.plot(x_test, y_test, 'b.', label='Reales')\n",
    "plt.plot(x_train, predictions, 'r.', label='Predecidos')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un nuevo modelo con 2 capas intermedias y 1 salida\n",
    "model_3 = tf.keras.Sequential()\n",
    "model_3.add(layers.Dense(16, activation='relu', input_shape=(1,)))\n",
    "model_3.add(layers.Dense(16, activation='relu'))\n",
    "model_3.add(layers.Dense(1))\n",
    "\n",
    "model_3.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "model_3.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamos el nuevo modelo mas complejo\n",
    "history_3 = model_3.fit(x_train, y_train, epochs=400, batch_size=16,\n",
    "                     validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficamos la perdida , epoch history_3\n",
    "loss = history_3.history['loss']\n",
    "val_loss = history_3.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Perdida en entrenamiento y validacion')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Perdida')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HACEMOS UN GRAFICO SIN LOS PRIMEROS 100 REGISTROS \n",
    "#usando los valores de loss normal y mae\n",
    "SKIP = 100\n",
    "\n",
    "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Perdida en entrenamiento y validacion')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "mae = history_3.history['mae']\n",
    "val_mae = history_3.history['val_mae']\n",
    "\n",
    "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Error Absoluto entrenamiento y validacion')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#calculo de la perdida del test dataset\n",
    "loss = model_3.evaluate(x_test, y_test)\n",
    "\n",
    "# Realizamos las predicciones\n",
    "predicciones = model_3.predict(x_test)\n",
    "\n",
    "# Graph the predictions against the actual values\n",
    "plt.clf()\n",
    "plt.title('Comparacion valores predecidos vs reales')\n",
    "plt.plot(x_test, y_test, 'b.', label='Real')\n",
    "plt.plot(x_test, predicciones, 'r.', label='Predecido')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
